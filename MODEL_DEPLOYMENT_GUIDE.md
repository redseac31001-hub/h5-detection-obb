# ğŸš€ YOLOæ¨¡å‹éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•ä¸ºé¤å…AIè¯†åˆ«ç³»ç»Ÿå‡†å¤‡ã€è½¬æ¢å’Œéƒ¨ç½²YOLOæ¨¡å‹ã€‚

## ğŸ“ æ¨¡å‹æ–‡ä»¶ç»“æ„

```
public/models/
â”œâ”€â”€ face_detection_model/
â”‚   â”œâ”€â”€ model.json              # TensorFlow.jsæ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ group1-shard1of1.bin    # æ¨¡å‹æƒé‡æ–‡ä»¶
â”‚   â””â”€â”€ model_info.json         # æ‰©å±•æ¨¡å‹ä¿¡æ¯
â”œâ”€â”€ plate_detection_model/
â”‚   â”œâ”€â”€ model.json              # TensorFlow.jsæ¨¡å‹é…ç½®  
â”‚   â”œâ”€â”€ group1-shard1of1.bin    # æ¨¡å‹æƒé‡æ–‡ä»¶
â”‚   â””â”€â”€ model_info.json         # æ‰©å±•æ¨¡å‹ä¿¡æ¯
â””â”€â”€ README.md                   # æ¨¡å‹è¯´æ˜æ–‡æ¡£
```

## ğŸ¯ æ¨¡å‹è¦æ±‚è§„èŒƒ

### äººè„¸æ£€æµ‹æ¨¡å‹
- **è¾“å…¥æ ¼å¼**: `[1, 640, 640, 3]` (æ‰¹æ¬¡, é«˜åº¦, å®½åº¦, é€šé“)
- **è¾“å‡ºæ ¼å¼**: `[1, N, 6]` (æ‰¹æ¬¡, æ£€æµ‹æ•°é‡, [x, y, w, h, confidence, class])
- **æ£€æµ‹ç±»åˆ«**: `["face"]`
- **æ¨èé˜ˆå€¼**: ç½®ä¿¡åº¦ 0.5, IoU 0.4
- **æœ€å¤§æ£€æµ‹æ•°**: 10

### é¤ç›˜æ£€æµ‹æ¨¡å‹  
- **è¾“å…¥æ ¼å¼**: `[1, 640, 640, 3]` (æ‰¹æ¬¡, é«˜åº¦, å®½åº¦, é€šé“)
- **è¾“å‡ºæ ¼å¼**: `[1, N, 85]` (æ‰¹æ¬¡, æ£€æµ‹æ•°é‡, [x, y, w, h, conf, class1, class2, ...])
- **æ£€æµ‹ç±»åˆ«**: é¤å…·ã€é£Ÿç‰©ã€é¥®å“ç­‰ (è¯¦è§model_info.json)
- **æ¨èé˜ˆå€¼**: ç½®ä¿¡åº¦ 0.6, IoU 0.5  
- **æœ€å¤§æ£€æµ‹æ•°**: 20
- **ä»·æ ¼æ˜ å°„**: æ”¯æŒæ¯ä¸ªç±»åˆ«çš„ä»·æ ¼é…ç½®

## ğŸ”„ æ¨¡å‹è½¬æ¢æµç¨‹

### æ–¹æ³•1: ä»ONNXè½¬æ¢ (æ¨è)

```bash
# 1. å®‰è£…ä¾èµ–
pip install tf2onnx tensorflow
npm install -g @tensorflow/tfjs-converter

# 2. ONNXè½¬TensorFlow SavedModel
python -m tf2onnx.convert \\
    --onnx your_model.onnx \\
    --output saved_model \\
    --inputs images:0 \\
    --outputs output0:0

# 3. SavedModelè½¬TensorFlow.js
tensorflowjs_converter \\
    --input_format=tf_saved_model \\
    --output_node_names='Identity,Identity_1,Identity_2' \\
    --saved_model_tags=serve \\
    saved_model \\
    ./public/models/face_detection_model
```

### æ–¹æ³•2: ä»PyTorchè½¬æ¢

```python
import torch
from ultralytics import YOLO

# åŠ è½½PyTorchæ¨¡å‹
model = YOLO('your_model.pt')

# å¯¼å‡ºä¸ºONNX
model.export(format='onnx', imgsz=640)

# ç„¶åæŒ‰æ–¹æ³•1ç»§ç»­è½¬æ¢
```

### æ–¹æ³•3: ä½¿ç”¨Ultralyticsç›´æ¥å¯¼å‡º

```python
from ultralytics import YOLO

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = YOLO('your_trained_model.pt')

# ç›´æ¥å¯¼å‡ºä¸ºTensorFlow.jsæ ¼å¼
model.export(format='tfjs', imgsz=640)
```

## ğŸ› ï¸ å¿«é€Ÿéƒ¨ç½²å·¥å…·

### ä½¿ç”¨æ¨¡å‹æ›¿æ¢è„šæœ¬

```bash
# å¤åˆ¶è„šæœ¬åˆ°å¯æ‰§è¡Œä½ç½®
cd restaurant-ai-system/scripts

# æ›¿æ¢äººè„¸æ£€æµ‹æ¨¡å‹
node replace_model.js --type face --model /path/to/your/face_model/model.json

# æ›¿æ¢é¤ç›˜æ£€æµ‹æ¨¡å‹  
node replace_model.js --type plate --model /path/to/your/plate_model/model.json

# æŸ¥çœ‹å¤‡ä»½åˆ—è¡¨
node replace_model.js --list-backups
```

### æ‰‹åŠ¨éƒ¨ç½²æ­¥éª¤

1. **å¤‡ä»½ç°æœ‰æ¨¡å‹**
   ```bash
   cp -r public/models/face_detection_model public/models/face_detection_model_backup
   ```

2. **å¤åˆ¶æ–°æ¨¡å‹æ–‡ä»¶**
   ```bash
   cp your_model/model.json public/models/face_detection_model/
   cp your_model/*.bin public/models/face_detection_model/
   ```

3. **æ›´æ–°æ¨¡å‹ä¿¡æ¯** (å¯é€‰)
   ```bash
   cp your_model/model_info.json public/models/face_detection_model/
   ```

## ğŸ“ æ¨¡å‹ä¿¡æ¯é…ç½®

### model_info.json ç¤ºä¾‹

```json
{
  "name": "YOLOv8n Face Detection",
  "version": "2.0.0",
  "description": "ä¼˜åŒ–çš„é¤å…äººè„¸æ£€æµ‹æ¨¡å‹",
  "input_shape": [1, 640, 640, 3],
  "output_shape": [1, 25200, 6],
  "classes": ["face"],
  "confidence_threshold": 0.6,
  "iou_threshold": 0.4,
  "max_detections": 10,
  "preprocessing": {
    "normalize": true,
    "mean": [0, 0, 0],
    "std": [255, 255, 255]
  },
  "postprocessing": {
    "format": "yolo",
    "bbox_format": "xywh_center",
    "output_format": "[x, y, w, h, confidence, class]"
  }
}
```

### é¤ç›˜æ¨¡å‹ä»·æ ¼é…ç½®

```json
{
  "price_mapping": {
    "rice": 12.0,
    "noodles": 18.0,
    "chicken": 28.0,
    "beef": 45.0,
    "vegetables": 15.0,
    "soup": 12.0,
    "drink": 8.0
  }
}
```

## ğŸ§ª æ¨¡å‹æµ‹è¯•éªŒè¯

### 1. åŸºæœ¬åŠ è½½æµ‹è¯•

```javascript
// åœ¨æµè§ˆå™¨æ§åˆ¶å°ä¸­æµ‹è¯•
const model = await tf.loadGraphModel('/models/face_detection_model/model.json');
console.log('æ¨¡å‹è¾“å…¥å½¢çŠ¶:', model.inputs[0].shape);
console.log('æ¨¡å‹è¾“å‡ºå½¢çŠ¶:', model.outputs[0].shape);
```

### 2. æ¨ç†æµ‹è¯•

```javascript
// åˆ›å»ºæµ‹è¯•è¾“å…¥
const testInput = tf.randomNormal([1, 640, 640, 3]);
const prediction = model.predict(testInput);
console.log('æ¨ç†è¾“å‡ºå½¢çŠ¶:', prediction.shape);
```

### 3. æ€§èƒ½æµ‹è¯•

```javascript
// æµ‹è¯•æ¨ç†æ—¶é—´
const start = performance.now();
const prediction = model.predict(testInput);
await prediction.data(); // ç­‰å¾…GPUè®¡ç®—å®Œæˆ
const inferenceTime = performance.now() - start;
console.log('æ¨ç†æ—¶é—´:', inferenceTime, 'ms');
```

## ğŸ›ï¸ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨¡å‹ä¼˜åŒ–

```bash
# é‡åŒ–æ¨¡å‹ä»¥å‡å°‘æ–‡ä»¶å¤§å°
tensorflowjs_converter \\
    --input_format=tf_saved_model \\
    --quantize_uint8 \\
    saved_model \\
    ./optimized_model
```

### 2. è¾“å…¥å°ºå¯¸ä¼˜åŒ–

- **640x640**: æ ‡å‡†å°ºå¯¸ï¼Œå¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦
- **416x416**: æ›´å¿«æ¨ç†ï¼Œé€‚åº¦ç²¾åº¦æŸå¤±
- **832x832**: æ›´é«˜ç²¾åº¦ï¼Œæ¨ç†è¾ƒæ…¢

### 3. æ‰¹å¤„ç†è®¾ç½®

```javascript
// ç¦ç”¨æ‰¹å¤„ç†ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
const model = await tf.loadGraphModel(modelUrl, {
  fromTFHub: false,
  weightPathPrefix: '',
  onProgress: (fraction, msg) => console.log(fraction, msg)
});
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```
   é”™è¯¯: Failed to fetch model.json
   è§£å†³: æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’ŒWebæœåŠ¡å™¨é…ç½®
   ```

2. **è¾“å…¥å½¢çŠ¶ä¸åŒ¹é…**
   ```
   é”™è¯¯: Input shape mismatch
   è§£å†³: éªŒè¯æ¨¡å‹è¾“å…¥è¦æ±‚ï¼Œè°ƒæ•´é¢„å¤„ç†ä»£ç 
   ```

3. **æ¨ç†ç»“æœå¼‚å¸¸**
   ```
   é”™è¯¯: æ£€æµ‹ç»“æœä¸ºç©ºæˆ–é”™è¯¯
   è§£å†³: æ£€æŸ¥åå¤„ç†é€»è¾‘ï¼Œç¡®è®¤ç±»åˆ«æ˜ å°„æ­£ç¡®
   ```

4. **æ€§èƒ½é—®é¢˜**
   ```
   é—®é¢˜: æ¨ç†é€Ÿåº¦æ…¢
   è§£å†³: å¯ç”¨WebGLåç«¯ï¼Œè€ƒè™‘æ¨¡å‹é‡åŒ–
   ```

### è°ƒè¯•å·¥å…·

```javascript
// å¯ç”¨TensorFlow.jsè°ƒè¯•
tf.ENV.set('DEBUG', true);

// æŸ¥çœ‹åç«¯ä¿¡æ¯
console.log('å½“å‰åç«¯:', tf.getBackend());
console.log('å¯ç”¨åç«¯:', tf.engine().backendNames);

// å†…å­˜ä½¿ç”¨ç›‘æ§
console.log('å†…å­˜ä½¿ç”¨:', tf.memory());
```

## ğŸ“Š æ¨¡å‹è¯„ä¼°æŒ‡æ ‡

### è¯„ä¼°è„šæœ¬ç¤ºä¾‹

```python
import json
import numpy as np
from sklearn.metrics import precision_recall_curve

def evaluate_model_performance(predictions, ground_truth):
    \"\"\"è¯„ä¼°æ¨¡å‹æ€§èƒ½\"\"\"
    
    # è®¡ç®—mAP
    map_50 = calculate_map(predictions, ground_truth, iou_threshold=0.5)
    map_75 = calculate_map(predictions, ground_truth, iou_threshold=0.75)
    
    # è®¡ç®—æ¨ç†æ—¶é—´
    inference_times = [pred['inference_time'] for pred in predictions]
    avg_inference_time = np.mean(inference_times)
    
    return {
        'mAP@0.5': map_50,
        'mAP@0.75': map_75,
        'avg_inference_time_ms': avg_inference_time,
        'total_detections': len(predictions)
    }
```

## ğŸš€ éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [ ] æ¨¡å‹æ–‡ä»¶å®Œæ•´ (model.json + .binæ–‡ä»¶)
- [ ] æ¨¡å‹ä¿¡æ¯é…ç½®æ­£ç¡® (model_info.json)
- [ ] è¾“å…¥è¾“å‡ºå½¢çŠ¶åŒ¹é…ç³»ç»Ÿè¦æ±‚
- [ ] ç±»åˆ«æ˜ å°„é…ç½®å®Œæ•´
- [ ] ä»·æ ¼æ˜ å°„è®¾ç½®æ­£ç¡® (é¤ç›˜æ¨¡å‹)
- [ ] æ¨¡å‹åŠ è½½æµ‹è¯•é€šè¿‡
- [ ] æ¨ç†æµ‹è¯•æ­£å¸¸
- [ ] æ€§èƒ½æ»¡è¶³è¦æ±‚ (<200msæ¨ç†æ—¶é—´)
- [ ] å¤‡ä»½åŸæ¨¡å‹æ–‡ä»¶
- [ ] æ›´æ–°ç‰ˆæœ¬å·å’Œæ–‡æ¡£

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°éƒ¨ç½²é—®é¢˜ï¼Œè¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. æ¨¡å‹æ¥æºå’Œè®­ç»ƒæ¡†æ¶
2. è½¬æ¢è¿‡ç¨‹å’Œä½¿ç”¨çš„å·¥å…·ç‰ˆæœ¬
3. é”™è¯¯æ—¥å¿—å’Œæ§åˆ¶å°è¾“å‡º
4. æµè§ˆå™¨ç‰ˆæœ¬å’Œè®¾å¤‡ä¿¡æ¯
5. æ¨¡å‹æ–‡ä»¶å¤§å°å’Œç»“æ„

---

**æ›´æ–°æ—¶é—´**: 2024å¹´12æœˆ  
**é€‚ç”¨ç‰ˆæœ¬**: v1.0.0+